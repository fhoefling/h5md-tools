#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright © 2010  Felix Höfling
#
# compute time averages of macroscopic state variables
# from .msv output file produced by HAL's MD package
#

from numpy import *
from math import pi
import tables, argparse
#import sys

description = {
    'c_V': 'isochoric specific heat',
    'chi_T': 'isothermal compressibility',
    'chi_S': 'adiabatic compressibility',
}

def main():
    # parse command line options
    args = parse_args()

    # construct header of table
    if args.table:
        header = '# Density  Cutoff   '
        for dset in args.datasets:
            name = dset[0].upper() + dset[1:].lower()
            header = header + name + '  err(' + name + ')   '
            name = 'Δ' + name
            header = header + name + '  err(' + name + ')   '

        # optional response coefficients
        coeff = []
        if args.ensemble == 'nve':
            'TEMP' in args.datasets and coeff.append('c_V')
            set(('TEMP','PRESS','XVIR')).issubset(args.datasets) and coeff.append('chi_S')
        elif args.ensemble == 'nvt':
            set(('TEMP','EPOT')).issubset(args.datasets) and coeff.append('c_V')
            set(('TEMP','PRESS','XVIR')).issubset(args.datasets) and coeff.append('chi_T')
        for name in coeff:
            header = header + name + '  err(' + name + ')   '

        print header

    # equilibrium or stationary property
    for i, fn in enumerate(args.input):
        try:
            f = tables.openFile(fn, mode='r')
        except IOError:
            raise SystemExit('failed to open HDF5 file: %s' % fn)

        H5 = f.root
        msv_mean = dict()      # mean values of observable
        msv_std = dict()       # standard deviation of observable (fluctuations)
        try:
            # read parameters
            dimension = H5.param.box._v_attrs.dimension
            density = H5.param.box._v_attrs.density
            npart = sum(H5.param.box._v_attrs.particles)
            cutoff = H5.param.lennard_jones._v_attrs.cutoff[0]

            if args.table:
                print '%.4g  %.3g\t' % (density, cutoff),
            else:
                print 'Filename: %s' % fn
                print 'Cutoff: %.3g' % cutoff
                print 'Density: %.4g' % density

            # iterate over datasets
            for dset in args.datasets:
                data = H5._v_leaves[dset]

                # skip first number of values
                if len(data.shape) > 1:
                    values = data[args.skip:, args.skip:]
                else:
                    values = data[args.skip:]

                if dset == 'VCM':
                    # calculate magnitude of center of mass velocity
                    values = sqrt(sum(prod([values, values], axis=0), axis=1))

                # compute error from different blocks
                # divide data in blocks
                if len(values) > args.blocks:
                    # cut size of data to a multiple of args.blocks
                    a = int(args.blocks * floor(len(values) / args.blocks))
                    values = reshape(values[:a], (args.blocks, -1))
                else:
                    values = reshape(values, (1, -1))

                # compute mean and standard deviation as well as error estimates
                mean_values = [
                    mean(values),
                    std(mean(values, axis=1)) / sqrt(args.blocks - 1)
                ]
                std_values = [
                    std(values),
                    std(std(values, axis=1)) / sqrt(args.blocks - 1)
                ]

                if args.table:
                    print '%.5g %.5g  ' % tuple(mean_values),
                    print '%.5g %.5g  ' % tuple(std_values),
                else:
                    try:
                        desc = H5._v_leaves[dset]._v_attrs.description
                    except tables.exceptions.NoSuchNodeError:
                        desc = dset.lower()
                    print '%s: %.4g ± %.3g' % (desc.capitalize(), mean_values[0], mean_values[1])
                    print '  Δ%s: %.4g ± %.3g' % (dset.capitalize(), std_values[0], std_values[1])

                # store in dictionary for later use
                msv_mean[dset] = mean_values
                msv_std[dset] = std_values

            # tail correction for truncated Lennard-Jones potential
            if False:  # disabled
                rc3i = 1 / pow(cutoff, 3)
                en_corr = (8./9) * pi * density * (rc3i * rc3i - 3.) * rc3i
                press_corr = (32./9) * pi * pow(density, 2) * (rc3i * rc3i - 1.5) * rc3i
                print '%.5g  ' % (msv_mean['EPOT'][0] + en_corr),
                print '%.5g  ' % (msv_mean['PRESS'][0] + press_corr)

            # compute response coefficients
            if args.ensemble:
                coeff = {}
                # specific heat in the microcanonical ensemble (NVE)
                if args.ensemble == 'nve' and 'TEMP' in msv_mean.keys():
                    DeltaT_over_T = msv_std['TEMP'][0] / msv_mean['TEMP'][0]
                    DeltaT_err = msv_std['TEMP'][1]
                    temp_err = msv_mean['TEMP'][1]
                    coeff['c_V'] = [
                        1 / (2./3 - npart * pow(DeltaT_over_T, 2)),
                        0    # error estimate
                    ]

                # specific heat in the canonical ensemble (NVT)
                if args.ensemble == 'nvt' and set(('TEMP','EPOT')).issubset(msv_mean.keys()):
                    temp = msv_mean['TEMP'][0]
                    temp_err = msv_mean['TEMP'][1]
                    Delta_Epot = msv_std['EPOT'][0]
                    Delta_Epot_err = msv_std['EPOT'][1]
                    Cv_ = npart * pow(Delta_Epot/temp, 2)
                    coeff['c_V'] = [
                        .5 * dimension + Cv_,
                        Cv_ * sqrt(pow(2 * temp_err / temp, 2) + pow(2 * Delta_Epot_err / Delta_Epot, 2))     # error estimate
                    ]

                # adiabatic compressibility in the microcanonical ensemble (NVE)
                if args.ensemble == 'nve' and set(('TEMP','PRESS','XVIR')).issubset(msv_mean.keys()):
                    temp = msv_mean['TEMP'][0]
                    press = msv_mean['PRESS'][0]
                    DeltaP = msv_std['PRESS'][0]
                    hypervirial = msv_mean['XVIR'][0]
                    coeff['chi_S'] = [
                        1 / (2. / dimension * temp * density + press + hypervirial
                             - DeltaP * DeltaP * npart / density / temp),
                        0    # error estimate
                    ]

                # isothermal compressibility in the canonical ensemble (NVT)
                if args.ensemble == 'nvt' and set(('TEMP','PRESS','XVIR')).issubset(msv_mean.keys()):
                    temp = msv_mean['TEMP'][0]
                    press = msv_mean['PRESS'][0]
                    DeltaP = msv_std['PRESS'][0]
                    hypervirial = msv_mean['XVIR'][0]
                    coeff['chi_T'] = [
                        1 / (2. / dimension * temp * density + press + hypervirial
                             - DeltaP * DeltaP * npart / density / temp),
                        0    # error estimate
                    ]

                for name in coeff.keys():
                    if args.table:
                        print '%.5g %.5g  ' % tuple(coeff[name]),
                    else:
                        desc = description[name].capitalize()
                        print '%s: %.4g ± %.3g' % (desc, coeff[name][0], coeff[name][1])

            # finish output line
            print

        except tables.exceptions.NoSuchNodeError:
            print 'missing simulation data in file: %s' % fn
            print 'Skipped\n'

        finally:
            f.close()

def parse_args():
    parser = argparse.ArgumentParser(prog='compute_msv')
    parser.add_argument('input', metavar='INPUT', nargs='+', help='HDF5 .msv file')
    parser.add_argument('--datasets', metavar='NAME', nargs='+', help='list of data sets')
    parser.add_argument('--blocks', type=int, help='number of blocks for error estimate')
    parser.add_argument('--skip', type=int, help='number of data points to skip from the beginning')
    parser.add_argument('--table', action='store_true', help='output results in table format')
    parser.add_argument('--ensemble', metavar='TYPE', choices=['nvt', 'nve'], help='compute response coefficients for specified ensemble')
    parser.set_defaults(
        datasets=('TEMP', 'PRESS', 'EPOT'),
        blocks=10,
        skip=0,
        tables=False,
    )
    return parser.parse_args()

if __name__ == '__main__':
    main()
