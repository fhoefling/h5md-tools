#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright © 2011  Felix Höfling
#
# concatenate trajectory samples from different H5MD files
#
# The param group is copied from the first file, only /param/box is adjusted accordingly.
# Currently, only a single particle species is supported.
#

from numpy import *
from os.path import basename
import argparse
import h5py

def main():
    # parse command line options
    args = parse_args()

    if len(args.input) < 2:
        print 'Need 2 input files at least'
        return

    # open output file
    try:
        of = h5py.File(args.output, 'w')
    except IOError:
        raise SystemExit('Failed to write HDF5 file: %s' % fn)

    try:
        # create group 'trajectory'
        H5out = of.create_group('trajectory/A')

        # open input files
        input = []
        box_length = []
        for i, fn in enumerate(args.input):
            try:
                f = h5py.File(fn, 'r')
            except IOError:
                print 'Failed to open HDF5 file: %s' % fn
                print 'Skipped\n'
                continue
            H5in = f['trajectory/A']

            try:
                # on first input file
                if i == 0:
                    # copy group 'h5md' # FIXME these entries should be updated
                    f.copy('h5md', of)
                    # copy group 'halmd'
                    f.copy('halmd', of)
                    dimension = of['halmd/box'].attrs['dimension']
                    # copy group 'box'
                    f.copy('trajectory/box', of['trajectory'])
                    # create group 'time' and append time stamp of last sample
                    shape = H5in['position/time'].shape # workaround reverse slicing bug
                    group = H5out.require_group('position')
                    ds = group.create_dataset('time', data=(H5in['position/time'][shape[0]-1],), maxshape=(None,))
                    H5out.require_group('velocity')['time'] = ds # make hard link
                    ds = group.create_dataset('step', data=(H5in['position/step'][shape[0]-1],), maxshape=(None,))
                    H5out.require_group('velocity')['step'] = ds
                else:
                    # check that dimension and box size are compatible
                    if f['halmd/box'].attrs['dimension'] != dimension:
                        raise SystemExit('Space dimension of input files must match')

                    idx, = where(abs(f['halmd/box'].attrs['length'] / box_length[0] - 1) > 1e-6)
                    if len(idx) > 0 and idx[0] != args.axis % dimension:
                        raise SystemExit('Box edges perpendicular to concatenation axis must match')

                input += [(f, H5in['position/sample'], H5in['velocity/sample'])]
                box_length += [f['halmd/box'].attrs['length']]

            except KeyError:
                f.close()
                raise SystemExit('Missing trajectory data in file: %s' % fn)

        # store input file names and spacing parameter
        group = of.create_group('h5md_cat/input')
        group.attrs.create('files', array([basename(f.filename) for (f,r,v) in input]), dtype=h5py.new_vlen(str))
        group.attrs.create('spacing', args.spacing)

        # concatenate positions:
        # string subsystems together along specified axis by appropriate shifts
        shift = -.5 * sum(array(box_length)[1:, args.axis])
        box_offset = shift - .5 * box_length[0][args.axis]

        position = ()
        for i,(f,r,v) in enumerate(input):
            L = box_length[i]
            r_ = r[args.sample] % L - .5 * L # map positions back to simulation box
            r_[..., args.axis] *= 1 - args.spacing / L[args.axis] # compress to allow for spacing
            r_[..., args.axis] += shift
            position += (r_,)
            shift += box_length[i][args.axis]
        position = concatenate(position)

        H5out.require_group('position').create_dataset(
            'sample', data=(position,),
            maxshape=(None,) + position.shape, dtype=input[0][1].dtype,
        )

        # concatenate velocities
        velocity = concatenate([v[args.sample] for (f,r,v) in input])
        H5out.require_group('velocity').create_dataset(
            'sample', data=(velocity,),
            maxshape=(None,) + velocity.shape, dtype=input[0][1].dtype,
        )

        # update box length, particle number, and average density
        box_length_ = box_length[0]
        box_length_[args.axis] = sum(array(box_length)[:, args.axis])
        of['halmd/box'].attrs.modify('length', box_length_)
        of['halmd/box'].attrs.modify('particles', array([position.shape[0],]))
        of['halmd/box'].attrs.modify('density', position.shape[0] / prod(box_length_)) 

        of['trajectory/box/edges'][args.axis, args.axis] = box_length_[args.axis]
        of['trajectory/box/offset'][args.axis] = box_offset

    finally:
        # close files
        of.close()
        for (f,r,v) in input:
            f.close()

def parse_args():
    parser = argparse.ArgumentParser(prog='h5md_cat')
    parser.add_argument('input', metavar='INPUT', nargs='+', help='HDF5 trajectory files')
    parser.add_argument('-o', '--output', required=True, help='output filename')
    parser.add_argument('--axis', default=-1, type=int, help='concatenation axis')
    parser.add_argument('--sample', default=-1, type=int, help='index of phase space sample')
    parser.add_argument('--spacing', default=0, type=float, help='spacing between concatenated samples')
    return parser.parse_args()

if __name__ == '__main__':
    main()
